{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_02_언어분석_영어_심화.ipynb의 사본의 사본",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SyaOTing/project/blob/main/%EC%97%B0%EC%84%A4%EB%AC%B8%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPW3raiFnGRY"
      },
      "source": [
        "# 환경 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVE_7ir2m8mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9193af7c-924e-43fe-d65b-2f15b5fc8408"
      },
      "source": [
        "# NLTK 세팅하기 \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wycgqiQspQEL"
      },
      "source": [
        "# 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXSbylvjpUXC"
      },
      "source": [
        "# 구글 드라이브 연결을 위한 기본 세팅 \n",
        "!pip install -U -q PyDrive\n",
        " \n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrxvTb0pkKR"
      },
      "source": [
        "## 문서 ID로 실제 파일 불러오기\n",
        "# 연설문 데이터\n",
        "## https://drive.google.com/file/d/1BlINRUrOmX7_q9ajB06wK0FBikRkuH5g/view?usp=sharing\n",
        "#\tid\tperson\tyear\ttext\n",
        "#\t1\tGeorge Walker Bush\t2000\tThank you very much.\\n\\nGood evening, my fello...\n",
        "#\t2\tGeorge Walker Bush\t2004\tThank you all. Thank you all for coming. We ha...\n",
        "#\t3\tBarack Obama\t2008\tHello, Chicago.\\n\\nIf there is anyone out ther...\n",
        "#\t4\tBarack Obama\t2012\tThank you. Thank you. Thank you so much.\\n\\nTo...\n",
        "#\t5\tDonald Trump\t2016\tThank you. Thank you very much, everybody. Sor...\n",
        "\n",
        "rawdata_downloaded = drive.CreateFile({'id': '1BlINRUrOmX7_q9ajB06wK0FBikRkuH5g'})\n",
        "rawdata_downloaded.GetContentFile('rawdata.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk186oQ5pwM4"
      },
      "source": [
        "# \"rawdata.txt\" 파일의 내용을 \"원본데이터\" 변수로 불러오기\n",
        "원본데이터 = pd.read_csv('rawdata.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC4ZKjPapy8w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6afb952d-744e-430e-d4cb-85d56e777a11"
      },
      "source": [
        "#@title 기본 제목 텍스트\n",
        "# \"원본데이터\" 변수 내용 확인하기\n",
        "원본데이터"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>decade</th>\n",
              "      <th>birth</th>\n",
              "      <th>years</th>\n",
              "      <th>gender</th>\n",
              "      <th>job</th>\n",
              "      <th>name</th>\n",
              "      <th>nation</th>\n",
              "      <th>event</th>\n",
              "      <th>text</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "      <th>Unnamed: 14</th>\n",
              "      <th>Unnamed: 15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020</td>\n",
              "      <td>2020s</td>\n",
              "      <td>1946</td>\n",
              "      <td>70s</td>\n",
              "      <td>M</td>\n",
              "      <td>president</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>USA</td>\n",
              "      <td>Press Conference on Executive Orders</td>\n",
              "      <td>Thank you very much everybody. Thank you, and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020</td>\n",
              "      <td>2020s</td>\n",
              "      <td>1946</td>\n",
              "      <td>70s</td>\n",
              "      <td>M</td>\n",
              "      <td>president</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>USA</td>\n",
              "      <td>Remarks at Salute to America</td>\n",
              "      <td>Wow. Are you having a good time? Members of Co...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020</td>\n",
              "      <td>2020s</td>\n",
              "      <td>1946</td>\n",
              "      <td>70s</td>\n",
              "      <td>M</td>\n",
              "      <td>president</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>USA</td>\n",
              "      <td>Campaign Rally in Tulsa, Oklahoma</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020</td>\n",
              "      <td>2020s</td>\n",
              "      <td>1946</td>\n",
              "      <td>70s</td>\n",
              "      <td>M</td>\n",
              "      <td>president</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>USA</td>\n",
              "      <td>Statement on Protests Against Police Brutality</td>\n",
              "      <td>Thank you very much. My fellow Americans: My f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020</td>\n",
              "      <td>2020s</td>\n",
              "      <td>1946</td>\n",
              "      <td>70s</td>\n",
              "      <td>M</td>\n",
              "      <td>president</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>USA</td>\n",
              "      <td>Task Force Briefing on the Coronavirus Pandemic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>1974</td>\n",
              "      <td>1970s</td>\n",
              "      <td>1924</td>\n",
              "      <td>50s</td>\n",
              "      <td>M</td>\n",
              "      <td>president</td>\n",
              "      <td>Gerald Ford</td>\n",
              "      <td>USA</td>\n",
              "      <td>Remarks on Taking the Oath of Office</td>\n",
              "      <td>Mr. Chief Justice, my dear friends, my fellow ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>1974</td>\n",
              "      <td>1970s</td>\n",
              "      <td>1924</td>\n",
              "      <td>50s</td>\n",
              "      <td>M</td>\n",
              "      <td>president</td>\n",
              "      <td>Gerald Ford</td>\n",
              "      <td>USA</td>\n",
              "      <td>Remarks on Departure From the White House</td>\n",
              "      <td>Members of the Cabinet, members of the White H...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>1974</td>\n",
              "      <td>1970s</td>\n",
              "      <td>1924</td>\n",
              "      <td>50s</td>\n",
              "      <td>M</td>\n",
              "      <td>president</td>\n",
              "      <td>Gerald Ford</td>\n",
              "      <td>USA</td>\n",
              "      <td>Address to the Nation Announcing Decision To R...</td>\n",
              "      <td>Good evening:\\nThis is the 37th time I have sp...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>1974</td>\n",
              "      <td>1970s</td>\n",
              "      <td>1924</td>\n",
              "      <td>50s</td>\n",
              "      <td>M</td>\n",
              "      <td>president</td>\n",
              "      <td>Gerald Ford</td>\n",
              "      <td>USA</td>\n",
              "      <td>Address to the Nation on Presidential Tape Rec...</td>\n",
              "      <td>Good evening:\\nI have asked for this time toni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>1974</td>\n",
              "      <td>1970s</td>\n",
              "      <td>1924</td>\n",
              "      <td>50s</td>\n",
              "      <td>M</td>\n",
              "      <td>president</td>\n",
              "      <td>Gerald Ford</td>\n",
              "      <td>USA</td>\n",
              "      <td>State of the Union Address</td>\n",
              "      <td>Mr. Speaker, Mr. President, my colleagues in t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>330 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     year decade  birth  ... Unnamed: 13 Unnamed: 14 Unnamed: 15\n",
              "0    2020  2020s   1946  ...         NaN         NaN         NaN\n",
              "1    2020  2020s   1946  ...         NaN         NaN         NaN\n",
              "2    2020  2020s   1946  ...         NaN         NaN         NaN\n",
              "3    2020  2020s   1946  ...         NaN         NaN         NaN\n",
              "4    2020  2020s   1946  ...         NaN         NaN         NaN\n",
              "..    ...    ...    ...  ...         ...         ...         ...\n",
              "325  1974  1970s   1924  ...         NaN         NaN         NaN\n",
              "326  1974  1970s   1924  ...         NaN         NaN         NaN\n",
              "327  1974  1970s   1924  ...         NaN         NaN         NaN\n",
              "328  1974  1970s   1924  ...         NaN         NaN         NaN\n",
              "329  1974  1970s   1924  ...         NaN         NaN         NaN\n",
              "\n",
              "[330 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9l61MS4npBc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "75d2cf00-62d2-4019-8fdb-4eb9a24b607d"
      },
      "source": [
        "# 형태소 분석\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "저장공간  = []\n",
        "for index, row in 원본데이터.iterrows():\n",
        "    textdata = row[9]\n",
        "    type = row[6]\n",
        "    형태소 = nltk.tokenize.word_tokenize(textdata)\n",
        "    형태소종합 = list(nltk.pos_tag(형태소))\n",
        "    형태소종합 = pd.DataFrame.from_records(형태소종합)\n",
        "    형태소종합['type'] = type\n",
        "    형태소종합['count'] = 1      \n",
        "    저장공간.append(형태소종합)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-5cf3c8f01975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtextdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0m형태소\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0m형태소종합\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m형태소\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0m형태소종합\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m형태소종합\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m     94\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# Standard word tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \"\"\"\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \"\"\"\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \"\"\"\n\u001b[1;32m   1315\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0msl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \"\"\"\n\u001b[1;32m    311\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_tok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqWXXkP2n94q",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6937b0b-5e95-4339-9f18-067efd05aa4b"
      },
      "source": [
        "#@title 기본 제목 텍스트\n",
        "# \"형태소\" 변수의 저장 내용 확인\n",
        "형태소"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow',\n",
              " '.',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'having',\n",
              " 'a',\n",
              " 'good',\n",
              " 'time',\n",
              " '?',\n",
              " 'Members',\n",
              " 'of',\n",
              " 'Congress',\n",
              " ',',\n",
              " 'members',\n",
              " 'of',\n",
              " 'my',\n",
              " 'cabinet',\n",
              " ',',\n",
              " 'and',\n",
              " 'my',\n",
              " 'fellow',\n",
              " 'Americans',\n",
              " ':',\n",
              " 'The',\n",
              " 'First',\n",
              " 'Lady',\n",
              " 'and',\n",
              " 'I',\n",
              " 'are',\n",
              " 'delighted',\n",
              " 'to',\n",
              " 'welcome',\n",
              " 'you',\n",
              " 'to',\n",
              " 'the',\n",
              " 'second',\n",
              " 'annual',\n",
              " 'Salute',\n",
              " 'to',\n",
              " 'America',\n",
              " '.',\n",
              " 'On',\n",
              " 'this',\n",
              " 'wonderful',\n",
              " 'day',\n",
              " ',',\n",
              " 'we',\n",
              " 'celebrate',\n",
              " 'our',\n",
              " 'history',\n",
              " ',',\n",
              " 'our',\n",
              " 'heroes',\n",
              " ',',\n",
              " 'our',\n",
              " 'heritage',\n",
              " ',',\n",
              " 'our',\n",
              " 'great',\n",
              " 'American',\n",
              " 'flag',\n",
              " ',',\n",
              " 'and',\n",
              " 'our',\n",
              " 'freedom',\n",
              " '.',\n",
              " 'Happy',\n",
              " 'Fourth',\n",
              " 'of',\n",
              " 'July',\n",
              " 'to',\n",
              " 'everyone',\n",
              " '.',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'thank',\n",
              " 'the',\n",
              " 'U.S.',\n",
              " 'Army',\n",
              " 'Golden',\n",
              " 'Knights',\n",
              " 'for',\n",
              " 'that',\n",
              " 'truly',\n",
              " 'awe-inspiring',\n",
              " 'display',\n",
              " '.',\n",
              " 'Tremendous',\n",
              " 'talent',\n",
              " '.',\n",
              " 'The',\n",
              " 'Golden',\n",
              " 'Knights',\n",
              " ',',\n",
              " 'and',\n",
              " 'every',\n",
              " 'member',\n",
              " 'of',\n",
              " 'the',\n",
              " 'Armed',\n",
              " 'Forces',\n",
              " 'here',\n",
              " 'this',\n",
              " 'evening',\n",
              " ',',\n",
              " 'we',\n",
              " 'just',\n",
              " 'want',\n",
              " 'to',\n",
              " 'say',\n",
              " 'that',\n",
              " 'you',\n",
              " 'have',\n",
              " 'earned',\n",
              " 'the',\n",
              " 'eternal',\n",
              " 'gratitude',\n",
              " 'of',\n",
              " 'our',\n",
              " 'entire',\n",
              " 'nation',\n",
              " '.',\n",
              " 'Two',\n",
              " 'hundred',\n",
              " 'and',\n",
              " 'forty-four',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'in',\n",
              " 'Philadelphia',\n",
              " ',',\n",
              " 'the',\n",
              " '56',\n",
              " 'signers',\n",
              " 'of',\n",
              " 'our',\n",
              " 'Declaration',\n",
              " 'of',\n",
              " 'Independence',\n",
              " 'pledged',\n",
              " 'their',\n",
              " 'lives',\n",
              " ',',\n",
              " 'their',\n",
              " 'fortunes',\n",
              " ',',\n",
              " 'and',\n",
              " 'their',\n",
              " 'sacred',\n",
              " 'honor',\n",
              " 'to',\n",
              " 'boldly',\n",
              " 'proclaim',\n",
              " 'this',\n",
              " 'eternal',\n",
              " 'truth',\n",
              " ':',\n",
              " 'that',\n",
              " 'we',\n",
              " 'are',\n",
              " 'all',\n",
              " 'made',\n",
              " 'equal',\n",
              " 'by',\n",
              " 'God',\n",
              " '.',\n",
              " 'Thanks',\n",
              " 'to',\n",
              " 'the',\n",
              " 'courage',\n",
              " 'of',\n",
              " 'those',\n",
              " 'patriots',\n",
              " 'of',\n",
              " 'July',\n",
              " '4th',\n",
              " ',',\n",
              " '1776',\n",
              " ',',\n",
              " 'the',\n",
              " 'American',\n",
              " 'Republic',\n",
              " 'stands',\n",
              " 'today',\n",
              " 'as',\n",
              " 'the',\n",
              " 'greatest',\n",
              " ',',\n",
              " 'most',\n",
              " 'exceptional',\n",
              " ',',\n",
              " 'and',\n",
              " 'most',\n",
              " 'virtuous',\n",
              " 'nation',\n",
              " 'in',\n",
              " 'the',\n",
              " 'history',\n",
              " 'of',\n",
              " 'the',\n",
              " 'world',\n",
              " '.',\n",
              " 'Our',\n",
              " 'workers',\n",
              " ',',\n",
              " 'our',\n",
              " 'factories',\n",
              " 'have',\n",
              " 'revolutionized',\n",
              " 'industries',\n",
              " 'and',\n",
              " 'lifted',\n",
              " 'millions',\n",
              " 'into',\n",
              " 'prosperity',\n",
              " '.',\n",
              " 'Our',\n",
              " 'artists',\n",
              " ',',\n",
              " 'architects',\n",
              " ',',\n",
              " 'and',\n",
              " 'engineers',\n",
              " 'have',\n",
              " 'inspired',\n",
              " 'the',\n",
              " 'globe',\n",
              " 'with',\n",
              " 'transcendent',\n",
              " 'works',\n",
              " 'of',\n",
              " 'beauty',\n",
              " '.',\n",
              " 'American',\n",
              " 'heroes',\n",
              " 'defeated',\n",
              " 'the',\n",
              " 'Nazis',\n",
              " ',',\n",
              " 'dethroned',\n",
              " 'the',\n",
              " 'fascists',\n",
              " ',',\n",
              " 'toppled',\n",
              " 'the',\n",
              " 'communists',\n",
              " ',',\n",
              " 'saved',\n",
              " 'American',\n",
              " 'values',\n",
              " ',',\n",
              " 'upheld',\n",
              " 'American',\n",
              " 'principles',\n",
              " ',',\n",
              " 'and',\n",
              " 'chased',\n",
              " 'down',\n",
              " 'the',\n",
              " 'terrorists',\n",
              " 'to',\n",
              " 'the',\n",
              " 'very',\n",
              " 'ends',\n",
              " 'of',\n",
              " 'the',\n",
              " 'Earth',\n",
              " '.',\n",
              " 'We',\n",
              " 'are',\n",
              " 'now',\n",
              " 'in',\n",
              " 'the',\n",
              " 'process',\n",
              " 'of',\n",
              " 'defeating',\n",
              " 'the',\n",
              " 'radical',\n",
              " 'left',\n",
              " ',',\n",
              " 'the',\n",
              " 'Marxists',\n",
              " ',',\n",
              " 'the',\n",
              " 'anarchists',\n",
              " ',',\n",
              " 'the',\n",
              " 'agitators',\n",
              " ',',\n",
              " 'the',\n",
              " 'looters',\n",
              " ',',\n",
              " 'and',\n",
              " 'people',\n",
              " 'who',\n",
              " ',',\n",
              " 'in',\n",
              " 'many',\n",
              " 'instances',\n",
              " ',',\n",
              " 'have',\n",
              " 'absolutely',\n",
              " 'no',\n",
              " 'clue',\n",
              " 'what',\n",
              " 'they',\n",
              " 'are',\n",
              " 'doing',\n",
              " '.',\n",
              " 'Our',\n",
              " 'inventors',\n",
              " ',',\n",
              " 'scientists',\n",
              " ',',\n",
              " 'doctors',\n",
              " ',',\n",
              " 'and',\n",
              " 'researchers',\n",
              " 'have',\n",
              " 'improved',\n",
              " 'the',\n",
              " 'lives',\n",
              " 'of',\n",
              " 'billions',\n",
              " 'and',\n",
              " 'billions',\n",
              " 'all',\n",
              " 'around',\n",
              " 'the',\n",
              " 'world',\n",
              " '.',\n",
              " 'Our',\n",
              " 'brave',\n",
              " 'astronauts',\n",
              " 'planted',\n",
              " 'the',\n",
              " 'American',\n",
              " 'flag',\n",
              " 'on',\n",
              " 'the',\n",
              " 'Moon',\n",
              " ',',\n",
              " 'and',\n",
              " 'America',\n",
              " 'will',\n",
              " 'be',\n",
              " 'the',\n",
              " 'first',\n",
              " 'nation',\n",
              " 'to',\n",
              " 'land',\n",
              " 'on',\n",
              " 'Mars',\n",
              " '.',\n",
              " 'All',\n",
              " 'Americans',\n",
              " 'living',\n",
              " 'today',\n",
              " 'are',\n",
              " 'the',\n",
              " 'heirs',\n",
              " 'of',\n",
              " 'this',\n",
              " 'magnificent',\n",
              " 'legacy',\n",
              " '.',\n",
              " 'We',\n",
              " 'are',\n",
              " 'the',\n",
              " 'descendants',\n",
              " 'of',\n",
              " 'the',\n",
              " 'most',\n",
              " 'daring',\n",
              " 'and',\n",
              " 'courageous',\n",
              " 'people',\n",
              " 'ever',\n",
              " 'to',\n",
              " 'walk',\n",
              " 'on',\n",
              " 'the',\n",
              " 'face',\n",
              " 'of',\n",
              " 'the',\n",
              " 'Earth',\n",
              " '.',\n",
              " 'We',\n",
              " 'inherit',\n",
              " 'their',\n",
              " 'towering',\n",
              " 'confidence',\n",
              " ',',\n",
              " 'unwavering',\n",
              " 'enthusiasm',\n",
              " ',',\n",
              " 'their',\n",
              " 'unbridled',\n",
              " 'ambition',\n",
              " ',',\n",
              " 'and',\n",
              " 'their',\n",
              " 'unrelenting',\n",
              " 'optimism',\n",
              " '.',\n",
              " 'This',\n",
              " 'is',\n",
              " 'the',\n",
              " 'untamed',\n",
              " 'spirit',\n",
              " 'that',\n",
              " 'built',\n",
              " 'this',\n",
              " 'glorious',\n",
              " 'nation',\n",
              " ',',\n",
              " 'and',\n",
              " 'this',\n",
              " 'is',\n",
              " 'the',\n",
              " 'spirit',\n",
              " 'that',\n",
              " 'burns',\n",
              " 'brightly',\n",
              " 'within',\n",
              " 'the',\n",
              " 'soul',\n",
              " 'of',\n",
              " 'every',\n",
              " 'American',\n",
              " 'patriot',\n",
              " '.',\n",
              " 'That',\n",
              " 'is',\n",
              " 'why',\n",
              " 'we',\n",
              " 'pay',\n",
              " 'tribute',\n",
              " 'to',\n",
              " 'generations',\n",
              " 'of',\n",
              " 'American',\n",
              " 'heroes',\n",
              " 'whose',\n",
              " 'names',\n",
              " 'are',\n",
              " 'etched',\n",
              " 'on',\n",
              " 'our',\n",
              " 'monuments',\n",
              " 'and',\n",
              " 'memorials',\n",
              " ',',\n",
              " 'and',\n",
              " 'in',\n",
              " 'the',\n",
              " 'pages',\n",
              " 'of',\n",
              " 'history',\n",
              " ',',\n",
              " 'and',\n",
              " 'in',\n",
              " 'the',\n",
              " 'hearts',\n",
              " 'of',\n",
              " 'a',\n",
              " 'very',\n",
              " 'grateful',\n",
              " 'people',\n",
              " '.',\n",
              " 'We',\n",
              " 'will',\n",
              " 'never',\n",
              " 'allow',\n",
              " 'an',\n",
              " 'angry',\n",
              " 'mob',\n",
              " 'to',\n",
              " 'tear',\n",
              " 'down',\n",
              " 'our',\n",
              " 'statues',\n",
              " ',',\n",
              " 'erase',\n",
              " 'our',\n",
              " 'history',\n",
              " ',',\n",
              " 'indoctrinate',\n",
              " 'our',\n",
              " 'children',\n",
              " ',',\n",
              " 'or',\n",
              " 'trample',\n",
              " 'on',\n",
              " 'our',\n",
              " 'freedoms',\n",
              " '.',\n",
              " 'We',\n",
              " 'will',\n",
              " 'safeguard',\n",
              " 'our',\n",
              " 'values',\n",
              " ',',\n",
              " 'traditions',\n",
              " ',',\n",
              " 'customs',\n",
              " ',',\n",
              " 'and',\n",
              " 'beliefs',\n",
              " '.',\n",
              " 'We',\n",
              " 'will',\n",
              " 'teach',\n",
              " 'our',\n",
              " 'children',\n",
              " 'to',\n",
              " 'cherish',\n",
              " 'and',\n",
              " 'adore',\n",
              " 'their',\n",
              " 'country',\n",
              " 'so',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'build',\n",
              " 'its',\n",
              " 'future',\n",
              " '.',\n",
              " 'Together',\n",
              " ',',\n",
              " 'we',\n",
              " 'will',\n",
              " 'fight',\n",
              " 'for',\n",
              " 'the',\n",
              " 'American',\n",
              " 'Dream',\n",
              " ',',\n",
              " 'and',\n",
              " 'we',\n",
              " 'will',\n",
              " 'defend',\n",
              " ',',\n",
              " 'protect',\n",
              " ',',\n",
              " 'and',\n",
              " 'preserve',\n",
              " 'American',\n",
              " 'way',\n",
              " 'of',\n",
              " 'life',\n",
              " ',',\n",
              " 'which',\n",
              " 'began',\n",
              " 'in',\n",
              " '1492',\n",
              " 'when',\n",
              " 'Columbus',\n",
              " 'discovered',\n",
              " 'America',\n",
              " '.',\n",
              " 'Jobs',\n",
              " 'and',\n",
              " 'companies',\n",
              " 'are',\n",
              " 'coming',\n",
              " 'back',\n",
              " 'to',\n",
              " 'our',\n",
              " 'country',\n",
              " 'like',\n",
              " 'never',\n",
              " 'before',\n",
              " '.',\n",
              " 'The',\n",
              " 'power',\n",
              " 'of',\n",
              " 'tariffs',\n",
              " 'being',\n",
              " 'imposed',\n",
              " 'on',\n",
              " 'foreign',\n",
              " 'lands',\n",
              " 'that',\n",
              " 'took',\n",
              " 'advantage',\n",
              " 'of',\n",
              " 'the',\n",
              " 'United',\n",
              " 'States',\n",
              " 'for',\n",
              " 'decades',\n",
              " 'and',\n",
              " 'decades',\n",
              " 'have',\n",
              " 'enabled',\n",
              " 'us',\n",
              " 'to',\n",
              " 'make',\n",
              " 'great',\n",
              " 'trade',\n",
              " 'deals',\n",
              " 'where',\n",
              " 'there',\n",
              " 'were',\n",
              " 'none',\n",
              " '.',\n",
              " 'Tens',\n",
              " 'of',\n",
              " 'billions',\n",
              " 'of',\n",
              " 'dollars',\n",
              " 'are',\n",
              " 'now',\n",
              " 'paid',\n",
              " 'to',\n",
              " 'the',\n",
              " 'United',\n",
              " 'States',\n",
              " 'Treasury',\n",
              " 'by',\n",
              " 'the',\n",
              " 'same',\n",
              " 'countries',\n",
              " '.',\n",
              " 'But',\n",
              " 'there',\n",
              " 'and',\n",
              " 'then',\n",
              " 'we',\n",
              " 'got',\n",
              " 'hit',\n",
              " 'by',\n",
              " 'the',\n",
              " 'virus',\n",
              " 'that',\n",
              " 'came',\n",
              " 'from',\n",
              " 'China',\n",
              " '.',\n",
              " 'And',\n",
              " 'we',\n",
              " '’',\n",
              " 've',\n",
              " 'made',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'progress',\n",
              " ';',\n",
              " 'our',\n",
              " 'strategy',\n",
              " 'is',\n",
              " 'moving',\n",
              " 'along',\n",
              " 'well',\n",
              " '.',\n",
              " 'It',\n",
              " 'goes',\n",
              " 'out',\n",
              " 'in',\n",
              " 'one',\n",
              " 'area',\n",
              " ',',\n",
              " 'and',\n",
              " 'rears',\n",
              " 'back',\n",
              " 'its',\n",
              " 'ugly',\n",
              " 'face',\n",
              " 'in',\n",
              " 'another',\n",
              " 'area',\n",
              " '.',\n",
              " 'But',\n",
              " 'we',\n",
              " '’',\n",
              " 've',\n",
              " 'learned',\n",
              " 'a',\n",
              " 'lot',\n",
              " '.',\n",
              " 'We',\n",
              " '’',\n",
              " 've',\n",
              " 'learned',\n",
              " 'how',\n",
              " 'to',\n",
              " 'put',\n",
              " 'out',\n",
              " 'the',\n",
              " 'flame',\n",
              " '.',\n",
              " 'We',\n",
              " '’',\n",
              " 've',\n",
              " 'made',\n",
              " 'ventilators',\n",
              " 'where',\n",
              " 'there',\n",
              " 'were',\n",
              " 'none',\n",
              " 'by',\n",
              " 'the',\n",
              " 'tens',\n",
              " 'of',\n",
              " 'thousands',\n",
              " ',',\n",
              " 'to',\n",
              " 'the',\n",
              " 'point',\n",
              " 'that',\n",
              " 'we',\n",
              " 'have',\n",
              " 'far',\n",
              " 'more',\n",
              " 'than',\n",
              " 'we',\n",
              " 'need',\n",
              " ',',\n",
              " 'and',\n",
              " 'we',\n",
              " 'are',\n",
              " 'now',\n",
              " 'distributing',\n",
              " 'them',\n",
              " 'to',\n",
              " 'many',\n",
              " 'foreign',\n",
              " 'countries',\n",
              " ',',\n",
              " 'as',\n",
              " 'a',\n",
              " 'gesture',\n",
              " 'of',\n",
              " 'goodwill',\n",
              " '.',\n",
              " 'Likewise',\n",
              " ',',\n",
              " 'testing',\n",
              " '—',\n",
              " 'there',\n",
              " 'were',\n",
              " 'no',\n",
              " 'tests',\n",
              " 'for',\n",
              " 'a',\n",
              " 'new',\n",
              " 'virus',\n",
              " ',',\n",
              " 'but',\n",
              " 'now',\n",
              " 'we',\n",
              " 'have',\n",
              " 'tested',\n",
              " 'over',\n",
              " '40',\n",
              " 'million',\n",
              " 'people',\n",
              " '.',\n",
              " 'But',\n",
              " 'by',\n",
              " 'so',\n",
              " 'doing',\n",
              " ',',\n",
              " 'we',\n",
              " 'show',\n",
              " 'cases',\n",
              " ',',\n",
              " '99',\n",
              " 'percent',\n",
              " 'of',\n",
              " 'which',\n",
              " 'are',\n",
              " 'totally',\n",
              " 'harmless',\n",
              " '.',\n",
              " 'Results',\n",
              " 'that',\n",
              " 'no',\n",
              " 'other',\n",
              " 'country',\n",
              " 'will',\n",
              " 'show',\n",
              " ',',\n",
              " 'because',\n",
              " 'no',\n",
              " 'other',\n",
              " 'country',\n",
              " 'has',\n",
              " 'testing',\n",
              " 'that',\n",
              " 'we',\n",
              " 'have',\n",
              " '—',\n",
              " 'not',\n",
              " 'in',\n",
              " 'terms',\n",
              " 'of',\n",
              " 'the',\n",
              " 'numbers',\n",
              " 'or',\n",
              " 'in',\n",
              " 'terms',\n",
              " 'of',\n",
              " 'the',\n",
              " 'quality',\n",
              " '.',\n",
              " 'And',\n",
              " 'now',\n",
              " ',',\n",
              " 'just',\n",
              " 'like',\n",
              " 'everything',\n",
              " 'else',\n",
              " ',',\n",
              " 'we',\n",
              " 'have',\n",
              " 'become',\n",
              " 'the',\n",
              " 'manufacturer',\n",
              " 'on',\n",
              " 'record',\n",
              " 'for',\n",
              " 'ventilators',\n",
              " ',',\n",
              " 'we',\n",
              " 'have',\n",
              " 'the',\n",
              " 'most',\n",
              " 'and',\n",
              " 'finest',\n",
              " 'testing',\n",
              " 'anywhere',\n",
              " 'in',\n",
              " 'the',\n",
              " 'world',\n",
              " ',',\n",
              " 'and',\n",
              " 'are',\n",
              " 'producing',\n",
              " 'gowns',\n",
              " 'and',\n",
              " 'masks',\n",
              " 'and',\n",
              " 'surgical',\n",
              " 'equipment',\n",
              " 'in',\n",
              " 'our',\n",
              " 'country',\n",
              " 'where',\n",
              " 'heretofore',\n",
              " 'it',\n",
              " 'was',\n",
              " 'almost',\n",
              " 'exclusively',\n",
              " 'made',\n",
              " 'in',\n",
              " 'foreign',\n",
              " 'lands',\n",
              " ',',\n",
              " 'in',\n",
              " 'particular',\n",
              " ',',\n",
              " 'China',\n",
              " ',',\n",
              " 'where',\n",
              " ',',\n",
              " 'ironically',\n",
              " ',',\n",
              " 'this',\n",
              " 'virus',\n",
              " 'and',\n",
              " 'others',\n",
              " 'came',\n",
              " 'from',\n",
              " '.',\n",
              " 'China',\n",
              " '’',\n",
              " 's',\n",
              " 'secrecy',\n",
              " ',',\n",
              " 'deceptions',\n",
              " ',',\n",
              " 'and',\n",
              " 'cover-up',\n",
              " 'allowed',\n",
              " 'it',\n",
              " 'to',\n",
              " 'spread',\n",
              " 'all',\n",
              " 'over',\n",
              " 'the',\n",
              " 'world',\n",
              " '—',\n",
              " '189',\n",
              " 'countries',\n",
              " '—',\n",
              " 'and',\n",
              " 'China',\n",
              " 'must',\n",
              " 'be',\n",
              " 'held',\n",
              " 'fully',\n",
              " 'accountable',\n",
              " '.',\n",
              " 'With',\n",
              " 'respect',\n",
              " 'to',\n",
              " 'remedies',\n",
              " ',',\n",
              " 'we',\n",
              " 'are',\n",
              " 'now',\n",
              " 'doing',\n",
              " 'unbelievably',\n",
              " 'well',\n",
              " ',',\n",
              " 'and',\n",
              " 'are',\n",
              " 'in',\n",
              " 'deep',\n",
              " 'testing',\n",
              " 'on',\n",
              " 'vaccines',\n",
              " ',',\n",
              " 'treatments',\n",
              " ',',\n",
              " 'and',\n",
              " 'therapeutics',\n",
              " '.',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'send',\n",
              " 'our',\n",
              " 'thanks',\n",
              " 'to',\n",
              " 'the',\n",
              " 'scientists',\n",
              " 'and',\n",
              " 'researchers',\n",
              " 'around',\n",
              " 'the',\n",
              " 'country',\n",
              " 'and',\n",
              " 'even',\n",
              " 'around',\n",
              " 'the',\n",
              " 'world',\n",
              " 'who',\n",
              " 'are',\n",
              " 'at',\n",
              " 'the',\n",
              " 'forefront',\n",
              " 'of',\n",
              " 'our',\n",
              " 'historic',\n",
              " 'effort',\n",
              " 'to',\n",
              " 'rapidly',\n",
              " 'develop',\n",
              " 'and',\n",
              " 'deliver',\n",
              " 'life-saving',\n",
              " 'treatments',\n",
              " 'and',\n",
              " ',',\n",
              " 'ultimately',\n",
              " ',',\n",
              " 'a',\n",
              " 'vaccine',\n",
              " '.',\n",
              " 'We',\n",
              " 'are',\n",
              " 'unleashing',\n",
              " 'our',\n",
              " 'nation',\n",
              " '’',\n",
              " 's',\n",
              " 'scientific',\n",
              " 'brilliance',\n",
              " '.',\n",
              " 'And',\n",
              " 'we',\n",
              " '’',\n",
              " 'll',\n",
              " 'likely',\n",
              " 'have',\n",
              " 'a',\n",
              " 'therapeutic',\n",
              " 'and/or',\n",
              " 'vaccine',\n",
              " 'solution',\n",
              " 'long',\n",
              " 'before',\n",
              " 'the',\n",
              " 'end',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfncYdYWn-_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "9dd75776-d09d-49af-d324-7eb9dc021e22"
      },
      "source": [
        "# \"형태소종합\" 변수의 저장 내용 확인\n",
        "형태소종합"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>type</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Are</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>you</td>\n",
              "      <td>PRP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>having</td>\n",
              "      <td>VBG</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3538</th>\n",
              "      <td>Thank</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3539</th>\n",
              "      <td>you</td>\n",
              "      <td>PRP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3540</th>\n",
              "      <td>very</td>\n",
              "      <td>RB</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3541</th>\n",
              "      <td>much</td>\n",
              "      <td>RB</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3543 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0    1          type  count\n",
              "0        Wow  NNP  Donald Trump      1\n",
              "1          .    .  Donald Trump      1\n",
              "2        Are  NNP  Donald Trump      1\n",
              "3        you  PRP  Donald Trump      1\n",
              "4     having  VBG  Donald Trump      1\n",
              "...      ...  ...           ...    ...\n",
              "3538   Thank  NNP  Donald Trump      1\n",
              "3539     you  PRP  Donald Trump      1\n",
              "3540    very   RB  Donald Trump      1\n",
              "3541    much   RB  Donald Trump      1\n",
              "3542       .    .  Donald Trump      1\n",
              "\n",
              "[3543 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcLQkYIboAuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052111e8-844a-45e7-f947-6f1af923364e"
      },
      "source": [
        "# \"저장공간\" 변수의 저장 내용 확인\n",
        "저장공간"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[                0    1          type  count\n",
              " 0           Thank  NNP  Donald Trump      1\n",
              " 1             you  PRP  Donald Trump      1\n",
              " 2            very   RB  Donald Trump      1\n",
              " 3            much   JJ  Donald Trump      1\n",
              " 4       everybody   NN  Donald Trump      1\n",
              " ...           ...  ...           ...    ...\n",
              " 5339           to   TO  Donald Trump      1\n",
              " 5340          the   DT  Donald Trump      1\n",
              " 5341  coronavirus   NN  Donald Trump      1\n",
              " 5342      disease   NN  Donald Trump      1\n",
              " 5343            .    .  Donald Trump      1\n",
              " \n",
              " [5344 rows x 4 columns],            0    1          type  count\n",
              " 0        Wow  NNP  Donald Trump      1\n",
              " 1          .    .  Donald Trump      1\n",
              " 2        Are  NNP  Donald Trump      1\n",
              " 3        you  PRP  Donald Trump      1\n",
              " 4     having  VBG  Donald Trump      1\n",
              " ...      ...  ...           ...    ...\n",
              " 3538   Thank  NNP  Donald Trump      1\n",
              " 3539     you  PRP  Donald Trump      1\n",
              " 3540    very   RB  Donald Trump      1\n",
              " 3541    much   RB  Donald Trump      1\n",
              " 3542       .    .  Donald Trump      1\n",
              " \n",
              " [3543 rows x 4 columns]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdBPFJoxoE4Q"
      },
      "source": [
        "# \"저장공간\" 변수의 내용을 데이터프레임 형식으로 변환해서 \"분석통합\" 변수에 저장한다.\n",
        "분석통합 = pd.concat(저장공간)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1knfULLboF5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "7646474c-d005-42b7-918a-94e4e32511b9"
      },
      "source": [
        "# \"분석통합\" 변수의 저장 내용 확인\n",
        "분석통합"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>type</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thank</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>you</td>\n",
              "      <td>PRP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>very</td>\n",
              "      <td>RB</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>much</td>\n",
              "      <td>JJ</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>everybody</td>\n",
              "      <td>NN</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3538</th>\n",
              "      <td>Thank</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3539</th>\n",
              "      <td>you</td>\n",
              "      <td>PRP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3540</th>\n",
              "      <td>very</td>\n",
              "      <td>RB</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3541</th>\n",
              "      <td>much</td>\n",
              "      <td>RB</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8887 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0    1          type  count\n",
              "0         Thank  NNP  Donald Trump      1\n",
              "1           you  PRP  Donald Trump      1\n",
              "2          very   RB  Donald Trump      1\n",
              "3          much   JJ  Donald Trump      1\n",
              "4     everybody   NN  Donald Trump      1\n",
              "...         ...  ...           ...    ...\n",
              "3538      Thank  NNP  Donald Trump      1\n",
              "3539        you  PRP  Donald Trump      1\n",
              "3540       very   RB  Donald Trump      1\n",
              "3541       much   RB  Donald Trump      1\n",
              "3542          .    .  Donald Trump      1\n",
              "\n",
              "[8887 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRyRe2kLoHH4"
      },
      "source": [
        "# \"분석통합\" 변수의 컬럼(열) 이름 변경\n",
        "분석통합.columns = [\"형태소\", \"품사\", \"분류\", \"카운트\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ziT3Z6ooILo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "2fdaa658-9cc2-4384-847e-5a50f99993af"
      },
      "source": [
        "# \"분석통합\" 변수의 저장 내용 확인\n",
        "분석통합"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>형태소</th>\n",
              "      <th>품사</th>\n",
              "      <th>분류</th>\n",
              "      <th>카운트</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thank</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>you</td>\n",
              "      <td>PRP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>very</td>\n",
              "      <td>RB</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>much</td>\n",
              "      <td>JJ</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>everybody</td>\n",
              "      <td>NN</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3538</th>\n",
              "      <td>Thank</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3539</th>\n",
              "      <td>you</td>\n",
              "      <td>PRP</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3540</th>\n",
              "      <td>very</td>\n",
              "      <td>RB</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3541</th>\n",
              "      <td>much</td>\n",
              "      <td>RB</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8887 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            형태소   품사            분류  카운트\n",
              "0         Thank  NNP  Donald Trump    1\n",
              "1           you  PRP  Donald Trump    1\n",
              "2          very   RB  Donald Trump    1\n",
              "3          much   JJ  Donald Trump    1\n",
              "4     everybody   NN  Donald Trump    1\n",
              "...         ...  ...           ...  ...\n",
              "3538      Thank  NNP  Donald Trump    1\n",
              "3539        you  PRP  Donald Trump    1\n",
              "3540       very   RB  Donald Trump    1\n",
              "3541       much   RB  Donald Trump    1\n",
              "3542          .    .  Donald Trump    1\n",
              "\n",
              "[8887 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCoRkBm_oJyo"
      },
      "source": [
        "# \"분석통합\" 변수의 내용을 형태소, 품사, 분류가 같은 것을 합치고, 카운트의 총합을 구해서 \"그룹통합\" 변수에 저장한다.\n",
        "그룹통합 = 분석통합.groupby(['형태소', '품사', \"분류\"])['카운트'].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM0GAI4HoOOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a8d12c-b2bb-44b8-a348-96cd2189f38c"
      },
      "source": [
        "# \"그룹통합\" 변수의 저장 내용 확인\n",
        "그룹통합"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "형태소  품사   분류          \n",
              "$    $    Donald Trump     11\n",
              "(    (    Donald Trump      3\n",
              ")    )    Donald Trump      3\n",
              ",    ,    Donald Trump    423\n",
              ".    .    Donald Trump    515\n",
              "                         ... \n",
              "”    ''   Donald Trump      1\n",
              "     JJ   Donald Trump      2\n",
              "     NNP  Donald Trump      1\n",
              "     NNS  Donald Trump      1\n",
              "     VB   Donald Trump      1\n",
              "Name: 카운트, Length: 1934, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byK936xmoPgP"
      },
      "source": [
        "# \"그룹통합\" 변수의 내용을 데이터프레임 형식으로 변환해서 \"그룹통합\" 변수에 저장한다.\n",
        "그룹통합 = pd.DataFrame(그룹통합)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYzT76hEoQ1P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "7c785322-6aa9-4eab-a3ae-ef34d9fe5fbb"
      },
      "source": [
        "# \"그룹통합\" 변수의 저장 내용 확인\n",
        "그룹통합"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>카운트</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>형태소</th>\n",
              "      <th>품사</th>\n",
              "      <th>분류</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>$</th>\n",
              "      <th>$</th>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(</th>\n",
              "      <th>(</th>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>)</th>\n",
              "      <th>)</th>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>,</th>\n",
              "      <th>,</th>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <th>.</th>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">”</th>\n",
              "      <th>''</th>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JJ</th>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NNP</th>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NNS</th>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VB</th>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1934 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      카운트\n",
              "형태소 품사  분류               \n",
              "$   $   Donald Trump   11\n",
              "(   (   Donald Trump    3\n",
              ")   )   Donald Trump    3\n",
              ",   ,   Donald Trump  423\n",
              ".   .   Donald Trump  515\n",
              "...                   ...\n",
              "”   ''  Donald Trump    1\n",
              "    JJ  Donald Trump    2\n",
              "    NNP Donald Trump    1\n",
              "    NNS Donald Trump    1\n",
              "    VB  Donald Trump    1\n",
              "\n",
              "[1934 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmPxEQHUoRvn"
      },
      "source": [
        "# \"그룹통합\" 변수의 내용을 \"형태소분석결과.csv\" 파일로 저장한다.\n",
        "# header는 컬럼(열) 정보의 포함 여부이다.\n",
        "# encoding은 문자코드를 선택하는 것이다. python에서는 기본적으로 utf-8(유니코드)를 사용한다.\n",
        "\n",
        "그룹통합.to_csv('형태소분석결과.csv', header='true', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}